{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real_Time_Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For use on NASDAQ real time data. \n",
    "- Import NASDAQ real time data to html files.  Store files in a central folder with script, before running.\n",
    "\n",
    "Notes:\n",
    "- I have completed two parts of this script.  \n",
    "     - Part one: Download NASDAQ real-time quotes as html.  Run Part one to combine all html into one txt file,   called result.txt.  The script then extracts the time, price and volume data from the txt.  If the script does not produce this error and you encounter no other errors, check the expressions to make sure they fit the data.  \n",
    "     - Part two: This part creates a data frame from the extracted data, which is in a file called extract.txt.  Some data clean-up, transformation and reorganizing is done during this step.  \n",
    "     - Part three: Not complete. This part will visualize the real-time data by volume and price.\n",
    "     - Part four: Not complete.  This part will visualize the yearly data by day.  This can be downloaded from NASDAW historical data.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Import, merge, extract data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Import libraries\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'DUST_10042018_RT.csv'\n",
    "date = '2018-10-04'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Read in files\n",
    "read_files = glob.glob(\"*.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Merge files into one txt\n",
    "with open(\"result.txt\", \"wb\") as outfile:\n",
    "    for f in read_files:\n",
    "        with open(f, \"rb\") as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Close file to free up memory\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5: Open text and view results\n",
    "with open ('result.txt', 'rt') as in_file:  # Open file lorem.txt for reading of text data.\n",
    "    contents = in_file.read()# Read the entire file into a variable named contents.\n",
    "#print(contents) # Print contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6: Test regex search in simple string\n",
    "str = \"volume.\"\n",
    "pat = re.compile(r\"\\bv\\w*e\\b\", re.IGNORECASE)\n",
    "if pat.search(str) != None: # Search for the pattern. If the result is NOT false,\n",
    "    print(\"Found it.\") # report a positive result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Step 7: Extract real time stock data \n",
    "f1 = open('result.txt', 'r')\n",
    "f2 = open('extract.txt','a')\n",
    "match = re.compile(r'\\d{2}:\\d{2}:\\d{2}\\s\\s\\$\\s\\d{2}.{2,5}\\s\\s[0-9]{2,}\\s')\n",
    "#The following commented lines break the string into individual pieces for testing:\n",
    "#regex = re.compile(r'\\d{2}:\\d{2}:\\d{2}') #Find time of trade\n",
    "#regex = re.compile(r'\\s\\$\\s\\d{2}.{2,5}\\s') #Find price of shares\n",
    "#regex = re.compile(r'\\s\\d{2*}\\b') #Find volume of shares\n",
    "for line in f1:  \n",
    "    qoutes = match.findall(line)\n",
    "    for result in qoutes: \n",
    "        f2.write(result)\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 8: Close open files\n",
    "f2.close()\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2  - Create DateFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Import txt to Pandas Dataframe and view \n",
    "data = pd.read_csv('extract.txt', sep='\\t', header=None)\n",
    "data.columns = [\"Time\", \"Price\", \"Volume\"] #Set column names\n",
    "data.head(5) #View first 5 rows of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(5) #View last 5 rows for dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2a: Get structure and description of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() #Identify dataframe structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe() #View statistical description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Wrangle data\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'] = pd.Timestamp(date) #Add date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_check = ['Price']\n",
    "data[cols_to_check] = data[cols_to_check].replace({'\\$':''}, regex=True)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Price=pd.to_numeric(data.Price)\n",
    "#pd.to_timedelta(Time +':00')\n",
    "#data['Time'] = pd.to_datetime.time(data['Time'])\n",
    "#data.Time = pd.to_datetime(data.Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes #Identify dataframe structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['Date',\"Time\", \"Price\", \"Volume\"]] #Arrange columns in logical order\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(['Time'],inplace=True) #Sort values ascending\n",
    "data.head(10) #Review changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Output to csv\n",
    "data.to_csv(file_name, sep='\\t', encoding='utf-8',header=True, columns=[\"Date\",\"Time\",\"Price\",\"Volume\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 - Visualize Real-Time data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 - Historic Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price Charts\n",
    "- 30 days\n",
    "\n",
    "- 90 days\n",
    "\n",
    "- 6 Months\n",
    "\n",
    "- 1 Year\n",
    "\n",
    "- 2 Years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Read files to dataframe\n",
    "hq = pd.read_csv('JNUG_Historical_Quotes.csv')\n",
    "hq = hq[['date',\"open\", \"high\", 'low', 'close', 'volume']] #Arrange columns in logical order\n",
    "hq.sort_values(['date'],inplace=True) #Sort values ascending\n",
    "hq.head(10) #Review changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq.to_csv('hq.csv', encoding='utf-8',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq1 = pd.read_csv('hq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hq1['MA50'] = hq1['close'].rolling(50).mean()\n",
    "hq1['MA200'] = hq1['close'].rolling(200).mean()\n",
    "hq1[['close', 'MA50', 'MA200']].plot(label='JNUG', figsize = (16,8), title = 'JNUG 2 Year Closing Price Chart')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
